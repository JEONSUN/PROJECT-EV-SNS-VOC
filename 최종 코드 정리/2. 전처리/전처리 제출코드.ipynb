{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a171026f"
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b13d879"
   },
   "source": [
    "#### * 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80a7c4c1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9faa9c63"
   },
   "source": [
    "#### * 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c83dfe6a"
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel('전기차_네이버블로그.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0fcfacc"
   },
   "source": [
    "#### * 'date'열 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6710d6b3"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime,date,time\n",
    "def t(x) :\n",
    "    if ('시간' in x) | ('분' in x) : \n",
    "        x = datetime(2021,7,27).strftime('%m.%d')\n",
    "    elif '일' in x:\n",
    "        x = datetime(2021,7,27 - int(x[0])).strftime('%m.%d')\n",
    "    elif '어제' in x:\n",
    "        x = datetime(2021,7,27 - 1).strftime('%m.%d')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4b28849"
   },
   "outputs": [],
   "source": [
    "data['date'] = data.date.apply(lambda x : t(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f10c4228"
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):    \n",
    "    if len(data['date'][i])==5:\n",
    "        data['date'][i]='2021.' + data['date'][i] # 2021년 붙여주기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be4e3f86"
   },
   "source": [
    "#### * 년, 월 변수생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "282386fd"
   },
   "outputs": [],
   "source": [
    "data['Year'] = data.days.apply(lambda x : int(x[:4]))\n",
    "data['Month'] = data.days.apply(lambda x : int(x[6:8])if x[7] != '.' else int(x[6:7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90a422c2"
   },
   "source": [
    "#### * 카페 공통문구 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96a763df"
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data['comment'][i]=data['comment'][i].replace('소중한 시간을 내어 답변해주시는 회원분들께 감사드립니다. 질문하기 전에 충분히 검색해보시고 그래도 해결되지 않는 문제가 있다면 다음 양식을 지켜 성실하게 질문해주시기 바랍니다. ','')\n",
    "\n",
    "    if data['comment'][i][0:3]=='관련된':\n",
    "        try:\n",
    "            data['comment'][i]=data['comment'][i].split('질문 내용')[1]\n",
    "        except:\n",
    "            try:\n",
    "                data['comment'][i]=data['comment'][i].split('전기차 종류')[1]\n",
    "            except:\n",
    "                try:\n",
    "                    data['comment'][i]=data['comment'][i].split('아니오')[1]\n",
    "                except:\n",
    "                    data['comment'][i]=data['comment'][i].split('네')[1]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4467490"
   },
   "outputs": [],
   "source": [
    "for i in data[(data.comment.str.contains('전기차 동호회 회원들의 질문과 답변은'))].index:\n",
    "    data['comment'][i]=data['comment'][i].replace('전기차 동호회 회원들의 질문과 답변은 여러 회원들께서 바쁜 시간을 내어 답변해주시고  정보가 쌓여 소중한 자료가 됩니다.  등업을 위해 의미 없는 게시글을  스팸성으로 반복해서 올리거나  답변이 달린 글을 임의 삭제하면 활동 제재가 될 수 있습니다.  게시글을 올리시기 전에 충분히 검색해보시고 그래도 해결되지 않는 문제가 있다면 다음 양식을 지켜 질문해주시기 바랍니다.  ','')\n",
    "    data['comment'][i]=data['comment'][i].replace('전기차 동호회 회원들의 질문과 답변은 여러 회원들께서 바쁜 시간을 내어 답변해주시고 정보가 쌓여 소중한 자료가 됩니다. 등업을 위해 의미 없는 게시글을 스팸성으로 반복해서 올리거나 답변이 달린 글을 임의 삭제하면 활동 제재가 될 수 있습니다. 게시글을 올리시기 전에 충분히 검색해보시고 그래도 해결되지 않는 문제가 있다면 다음 양식을 지켜 질문해주시기 바랍니다. ','')\n",
    "    data['comment'][i]=data['comment'][i].replace('전기차 동호회 회원들의 질문과 답변은 여러 회원들께서 바쁜 시간을 내어 답변해주시고  정보가 쌓여 소중한 자료가 됩니다.  등업을 위해 의미 없는 게시글을  스팸성으로 반복해서 올리거나  답변이 달린 글을 임의 삭제하면 활동 제재가 될 수 있습니다.  게시글을 올리시기 전에 충분히 검색해보시고 그래도 해결되지 않는 문제 가 있다면 다음 양식을 지켜 질문해주시기 바랍니다.  ','')\n",
    "\n",
    "    if data['comment'][i][0:3]=='관련된':\n",
    "        try:\n",
    "            data['comment'][i]=data['comment'][i].split('질문 내용')[1]\n",
    "        except:\n",
    "            try:\n",
    "                data['comment'][i]=data['comment'][i].split('전기차 종류 지역')[1]\n",
    "            except:\n",
    "                try:\n",
    "                    data['comment'][i]=data['comment'][i].split('아니오')[1]\n",
    "                except:\n",
    "                    data['comment'][i]=data['comment'][i].split('네')[1]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4de02137"
   },
   "source": [
    "#### * 중복 제거 & 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd153d01"
   },
   "outputs": [],
   "source": [
    "data=data.dropna(subset=['comment'])\n",
    "data=data.drop_duplicates(subset=['comment'])\n",
    "\n",
    "data=data.reset_index()\n",
    "data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcd6d244"
   },
   "source": [
    "#### 1. 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "604a3a90"
   },
   "outputs": [],
   "source": [
    "# 불필요한 문자 제거\n",
    "def clean_text(texts): \n",
    "    corpus = []\n",
    "    \n",
    "    for i in range(0, len(texts)):\n",
    "        review = texts[i]\n",
    "        \n",
    "        review = re.sub('\\d+\\:\\d+','', str(review)) # 타임스탬프 제거\n",
    "        review = re.sub(r'\\&quot\\;','', review) # quotation mark\n",
    "\n",
    "        \"\"\"\n",
    "        유튜브 전처리 추가부분\n",
    "\n",
    "        review = re.sub('_x000D_','', review) \n",
    "        review = re.sub(r'<br>',' ', review) # 줄바꿈은 공백으로 대체 \n",
    "\n",
    "        review = re.sub('\\+[A-Za-z가-힣0-9]+', '', review) #답글에서 상대 닉네임 언급 제거\n",
    "        review = re.sub('@[A-Za-z가-힣0-9]+', '', review) #답글에서 상대 닉네임 언급 제거\n",
    "        \n",
    "        review = BeautifulSoup(review, 'lxml').get_text() # Html 태그 제거\n",
    "        \"\"\"\n",
    "\n",
    "        review = review.upper()\n",
    "        review = re.sub(r'HTTP[A-Z]+','', review) # 링크 삭제\n",
    "\n",
    "        review = re.sub(r'[^A-Z가-힣0-9\\s.!?]+','', review) # 특수문자 및 이모티콘 제거\n",
    "        review = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]+','', review) # 자음 및 모음 제거\n",
    "        \n",
    "        review = re.sub(r'\\s+',' ', review) # 공백 제거\n",
    "        review = re.sub(r\"^\\s+\",'', review) # 시작 공백 제거\n",
    "        review = re.sub(r'\\s+$','', review) # 끝 공백 제거\n",
    "        corpus.append(review) \n",
    "        \n",
    "    return corpus\n",
    "\n",
    "comment = data.리뷰\n",
    "clean_comment = clean_text(comment)\n",
    "clean_comment_df = pd.DataFrame(clean_comment, columns = ['comment'])\n",
    "clean_comment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01adf607"
   },
   "source": [
    "#### 2. py-hanspell 맞춤법 교정 (네이버맞춤법 검사기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbc9bb85"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from hanspell import spell_checker\n",
    "from tqdm import tqdm\n",
    "\n",
    "hanspell_sent1 = \"\"\n",
    "mydataframe = pd.DataFrame()\n",
    "\n",
    "## 500자 제한 해결 코드\n",
    "for i in tqdm(range(len(clean_comment))) :\n",
    "    for j in range(math.ceil((len(clean_comment_df.comment[i])/500))) :\n",
    "        text = clean_comment_df.comment[i][500*j:500*(j+1)]\n",
    "        spelled_sent = spell_checker.check(text)\n",
    "        hanspell_sent = (spelled_sent.checked)\n",
    "        hanspell_sent1 = hanspell_sent1 + hanspell_sent\n",
    "\n",
    "    mydataframe = mydataframe.append([[hanspell_sent1]], ignore_index = True)\n",
    "    hanspell_sent1 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a30c811"
   },
   "source": [
    "#### 3. 광고 블로그 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e42f6946"
   },
   "outputs": [],
   "source": [
    "del_xls= pd.read_excel('del_blog.xlsx', header = None) # 광고 블로그 리스트 포함\n",
    "lst_xls = del_xls[0].apply(lambda x : x.split(','))\n",
    "\n",
    "\n",
    "def del_ad(x) :\n",
    "    y = \"\"\n",
    "    x = str(x)\n",
    "    \n",
    "    if x in lst_xls[0] :\n",
    "        return 'del_ad'\n",
    "    else :\n",
    "    \n",
    "        return x\n",
    "    \n",
    "data['no_names'] = data.names.apply(lambda x : del_ad(x))\n",
    "del_idx = data[data['no_names'] == 'del_ad'].index\n",
    "data.drop(del_idx, inplace = True)\n",
    "\n",
    "data = data.reset_index()\n",
    "data.drop(['no_names','index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d2d8c1b"
   },
   "source": [
    "#### 4. 불필요한 키워드 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4aba6fc"
   },
   "outputs": [],
   "source": [
    "titles = data.titles\n",
    "clean_comment = clean_text(titles)\n",
    "data['titles'] = clean_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "895642a4"
   },
   "outputs": [],
   "source": [
    "def del_blog_comment1(df) :\n",
    "    # 블로그 본문에 해당 키워드 포함 되어있으면 제거\n",
    "    comment_searchfor = ['주식','앱테크','부동산','맛집','호텔','숙소','버즈','증시','특징주'\\\n",
    "                         ,'코스피','코스닥','투어패스','우도','땅콩','금융','EW1','생태원',\\\n",
    "                         '민박','중국 생활',' 제주 살이','2채널','화성 탐사','화성탐사','캠핑용품','흑돼지','투자','뉴스','매수','수익',\\\n",
    "                        '비트코인','하늘공원','ETF','호텔','쿠팡','어린이','화장실','체험','이제이','방문','입구']\n",
    "    title_df = df[df.comment.str.contains('|'.join(comment_searchfor))]\n",
    "    comment_idx = df[df.comment.str.contains('|'.join(comment_searchfor))].index\n",
    "    \n",
    "    # x,y 합집합\n",
    "    union_func = lambda x,y : x.union(y)\n",
    "\n",
    "    # 특정 키워드가 블로그 제목에 들어가 있으면 제거 방지\n",
    "    no_del_idx = title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('시승'))].index\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('후기'))].index)# 단 여기서 출고를 지워야함(출고 후기가 대다수, 시공도 고민해봐야함)\n",
    "    # 테슬라\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('시승'))].index) # (어플, 고민해봐야함)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('주행'))].index) # 주식 지울것\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('리뷰')) & (title_df.comment.str.contains('MODEL'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('리뷰')) & (title_df.comment.str.contains('모델'))].index)\n",
    "    # 벤츠\n",
    "    no_del_idx = union_func(no_del_idx,title_df[title_df.titles.str.contains('EQA')].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[title_df.titles.str.contains('EQC')].index)\n",
    "    # 기아\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('후기'))].index) # 판매, 출고, 시공, 교체 ,장착\n",
    "    # 쉐보레\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('후기'))].index)  # 썬팅,선팅, 필름, 광택, 코팅\n",
    "    # 르노 삼성\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('리뷰'))].index)# 세차, 액자\n",
    "    # 포르쉐\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포르쉐')) & (title_df.titles.str.contains('후기'))].index) # 타공 카트 복원제 작업\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('타이칸')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('TAYCAN')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('타이칸')) & (title_df.titles.str.contains('리뷰'))].index) # 카러플\n",
    "    # BMW\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    # 푸조\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E208')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E208')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E208')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('시승')) & (title_df.titles.str.contains('2008'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('시승')) & (title_df.titles.str.contains('208'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('리뷰')) & (title_df.titles.str.contains('2008'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('리뷰')) & (title_df.titles.str.contains('208'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('후기')) & (title_df.titles.str.contains('2008'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('후기')) & (title_df.titles.str.contains('208'))].index)\n",
    "    # 현대코나\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('후기'))].index)# 선발주, 용접, 튜닝, 펄스레드, 컨티넨탈UC6,벤투스V2,토우바,우도여행,바디커버,코코나라,블루핸즈, 코나아이, 밧데리,일산풍산동타이어,제주그라벨호텔,자동차발수코팅제 \n",
    "    # 현대 포터 EV\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터 EV'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터 일렉트릭'))].index) # 그린서포터즈, 키워드,그린 서포터즈, 경쟁전략,서포터즈\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차 포터'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터2 일렉트릭'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터2'))].index)\n",
    "    # 봉고\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('봉고'))].index)\n",
    "    # 기타\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기자동차 서포터즈'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('주차장')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('휴게소')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('집밥'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    comment_idx = comment_idx.drop(no_del_idx)\n",
    "    df = df.drop(comment_idx)\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    #return title_df\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d03b5a6"
   },
   "outputs": [],
   "source": [
    "def del_blog_titles1(df) :\n",
    "    # 제목에 해당 키워드 포함 되어있으면 제거\n",
    "    titles_searchfor = ['피자','동굴','캠핑장','체험장','카트','전동기','스쿠터','겨울여행','가을여행','여름여행','코스트코',\\\n",
    "                        '도서','임대주택','타운하우스','책리뷰','서평','테마파크','가볼만한곳','아이나비',\\\n",
    "                        '네비게이션','카페','박물관','갈대','진로','면접','교육','하늘공원','열선','썬팅','인턴','매매',\\\n",
    "                        '중고차','할부','청춘','자전거','음악','선팅','필름','행사','관련주','뉴스','코인','리포트',\\\n",
    "                        '레고','SK이노베이션','SK 이노베이션','KT','음식','맛집','공기청정기','맛집','에어팟','칫솔','워셔액','카드','갤럭시','농장',\\\n",
    "                       '블루투스','청소기','TV','공사','카메라','산업기사','전기기사','공부','배송','자격증','수업','강사','합격',\\\n",
    "                       '강의','학과','전공','출고','어플','주식','판매','시공','교체','장착','OBD','에코파워캡','카마루6D',\\\n",
    "                        '티맵','마제스티9','솔라가드','자동차극장','킴스','썬팅','선팅','필름',\\\n",
    "                        '광택','코팅','세차','액자','타공','작업','카트','복원제','카러플','선발주','용접',\\\n",
    "                        '튜닝','펄스레드','컨티넨탈UC6','벤투스V2','토우바','우도여행','바디커버','코코나라',\\\n",
    "                        '블루핸즈','코나아이','밧데리','일산풍산동타이어','제주그라벨호텔','자동차발수코팅제','그린서포터즈',\\\n",
    "                        '키워드','그린 서포터즈','경쟁전략','서포터즈','샤오미','아마존','대통령','차량용','전문가','보고서','보험','밋업','보형','신문',\\\n",
    "                       '미세먼지','책 리뷰','일상','책','공원','짜장','인류','휴대폰','구독','글로벌','주차장','냉면','막국수','알칸타라핸들커버',\\\n",
    "                        '개업식','상생','주의사항','핫이슈','트렌드','번호판','무선','거치대','타이거','줄거리','영화','호텔','제품',\\\n",
    "                       '미국주식','TSMC','유모차','마켓','영업','도서','비즈니스','지수','데이트','다큐','왈라루','시청','CU','살아남기','GS25',\\\n",
    "                       '지구','노선','할인코드','백과','아울렛','이벤트','친구','펜션','코스','연료첨가제','선크림','포스팅','카시트','방향제',\\\n",
    "                        '화장실','코로나','종목','여객','버스','출사','한정판','종목','여객','뮤지엄','중국집','한정판','태블릿','패드','광고','프로젝트',\\\n",
    "                       '창업','방문','전시','촬영','입구','취업','매도','과정','산업','이야기','분야','연구','작품','사랑','다이슨','마인드','백서',\\\n",
    "                       '아웃렛']\n",
    "    \n",
    "    title_df = df[df.titles.str.contains('|'.join(titles_searchfor))]\n",
    "    title_idx = df[df.titles.str.contains('|'.join(titles_searchfor))].index\n",
    "    \n",
    "    # x,y 합집합\n",
    "    union_func = lambda x,y : x.union(y)\n",
    "\n",
    "    # 특정 키워드가 블로그 제목에 들어가 있으면 제거 방지\n",
    "    no_del_idx = title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('시승'))].index\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('아이오닉')) & (title_df.titles.str.contains('후기'))].index)# 단 여기서 출고를 지워야함(출고 후기가 대다수, 시공도 고민해봐야함)\n",
    "    # 테슬라\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('시승'))].index) # (어플, 고민해봐야함)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('주행'))].index) # 주식 지울것\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('리뷰')) & (title_df.comment.str.contains('MODEL'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(df.titles.str.contains('테슬라')) & (title_df.titles.str.contains('리뷰')) & (title_df.comment.str.contains('모델'))].index)\n",
    "    # 벤츠\n",
    "    no_del_idx = union_func(no_del_idx,title_df[title_df.titles.str.contains('EQA')].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[title_df.titles.str.contains('EQC')].index)\n",
    "    # 기아\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('쏘울')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('니로')) & (title_df.titles.str.contains('후기'))].index)# 판매, 출고, 시공, 교체 ,장착\n",
    "    # 쉐보레\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('볼트')) & (title_df.titles.str.contains('후기'))].index)  # 썬팅,선팅, 필름, 광택, 코팅\n",
    "    # 르노 삼성\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('르노')) & (title_df.titles.str.contains('리뷰'))].index)# 세차, 액자\n",
    "    # 포르쉐\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포르쉐')) & (title_df.titles.str.contains('후기'))].index) # 타공 카트 복원제 작업\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('타이칸')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('TAYCAN')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('타이칸')) & (title_df.titles.str.contains('리뷰'))].index) # 카러플\n",
    "    # BMW\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('I3')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    # 푸조\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E208')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E208')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E208')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('E2008')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('시승')) & (title_df.titles.str.contains('2008'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('시승')) & (title_df.titles.str.contains('208'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('리뷰')) & (title_df.titles.str.contains('2008'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('리뷰')) & (title_df.titles.str.contains('208'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('후기')) & (title_df.titles.str.contains('2008'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('푸조')) & (title_df.titles.str.contains('후기')) & (title_df.titles.str.contains('208'))].index)\n",
    "    # 현대코나\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('시승'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('코나')) & (title_df.titles.str.contains('후기'))].index)# 선발주, 용접, 튜닝, 펄스레드, 컨티넨탈UC6,벤투스V2,토우바,우도여행,바디커버,코코나라,블루핸즈, 코나아이, 밧데리,일산풍산동타이어,제주그라벨호텔,자동차발수코팅제 \n",
    "    # 현대 포터 EV\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터 EV'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터 일렉트릭'))].index) # 그린서포터즈, 키워드,그린 서포터즈, 경쟁전략,서포터즈\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차 포터'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터2 일렉트릭'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('포터2'))].index)\n",
    "    # 봉고\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('봉고'))].index)\n",
    "    # 기타\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기자동차 서포터즈'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기자동차')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기자동차')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기자동차')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기자동차')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기지동차')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기자동차')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('전기차')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('주차장')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('휴게소')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('집밥'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('주행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('사용'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('운행'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('리뷰'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('후기'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('롱텀')) & (title_df.titles.str.contains('충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('급속충전'))].index)\n",
    "    no_del_idx = union_func(no_del_idx,title_df[(title_df.titles.str.contains('완속충전'))].index)\n",
    "    title_idx = title_idx.drop(no_del_idx)\n",
    "\n",
    "    \n",
    "    df = df.drop(title_idx)\n",
    "        \n",
    "    #return title_df\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f29b6e3a"
   },
   "outputs": [],
   "source": [
    "data1 = del_blog_comment(data)\n",
    "data1 = data1.reset_index()\n",
    "data1.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c435d758"
   },
   "outputs": [],
   "source": [
    "data = del_blog_titles(data1)\n",
    "data = data.reset_index()\n",
    "data.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a512e39"
   },
   "source": [
    "#### 5. soynlp로 '복합명사'(빈도수 기준으로) 추출 -> mecab 사용자사전에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "504b98bf"
   },
   "outputs": [],
   "source": [
    "import soynlp\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "\n",
    "sents=data['comment'].values\n",
    "\n",
    "noun_extractor = LRNounExtractor_v2(verbose=True)\n",
    "nouns = noun_extractor.train_extract(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00a0fba9"
   },
   "outputs": [],
   "source": [
    "lower_count = 1000\n",
    "lower_score = 0.5\n",
    "new_noun = []\n",
    "for noun in nouns:\n",
    "    if (nouns[noun][0] >= lower_count) and (nouns[noun][1]) >= lower_score:\n",
    "        new_noun.append(noun)\n",
    "new_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6669d4f3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "non_noun_eomi_list = ('야', '고', '는', '까', '한', '인', '들', '이', '면', '로', '은', '히', '게')\n",
    "new_noun = set([item.strip(\"\"\"\"',.‘“△[]()”’ \"\"\") for item in new_noun \\\n",
    "                if (item[-1] not in non_noun_eomi_list) &  # 끝 단어가 eomi_list에 없고 \n",
    "                (sum([1 if char.isdigit() else 0 for char in item]) <= 2) & # 숫자가 두 개 이하\n",
    "                (len(re.sub('[^가-힣A-Z]', '', item)) >= 3) & # 한글과 알파벳이 3개 이상으로 이루어진\n",
    "                (not re.search('[^가-힣0-9A-Z]', item))]) # 한글,숫자,알파벳 제외한 것을 가지지 않는"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d89e5664"
   },
   "outputs": [],
   "source": [
    "from jamo import h2j, j2hcj  ##받침여부 포함하는 코드\n",
    "\n",
    "def get_jongsung_TF(sample_text): \n",
    "    sample_text_list = list(sample_text) \n",
    "    last_word = sample_text_list[-1] \n",
    "    last_word_jamo_list = list(j2hcj(h2j(last_word))) \n",
    "    last_jamo = last_word_jamo_list[-1] \n",
    "    \n",
    "    jongsung_TF = \"T\" \n",
    "\n",
    "    if last_jamo in ['ㅏ', 'ㅑ', 'ㅓ', 'ㅕ', 'ㅗ', 'ㅛ', 'ㅜ', 'ㅠ', 'ㅡ', 'ㅣ', 'ㅘ', 'ㅚ', 'ㅙ', 'ㅝ', 'ㅞ', 'ㅢ', 'ㅐ,ㅔ', 'ㅟ', 'ㅖ', 'ㅒ']: \n",
    "        jongsung_TF = \"F\" \n",
    "    \n",
    "    return jongsung_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cbb87a3"
   },
   "outputs": [],
   "source": [
    "#Save to Mecab \n",
    "f1 = open(r'C:\\mecab\\user-dic\\custom1.csv', 'w')\n",
    "add=['사용기','세컨드','롱레인지','풀옵션','집밥','플랫폼', '실주행', '내구성', '반자율', '시승기', '현기', '아이오닉', '아이오닉5', '충전', '전기분해', '불가능', '내연기관', \n",
    "     '트위지', '제로백', '사이드미러', '킥보드', '전기차', '재활용', '니로', '그랜져', '프렁크', '방지턱', '스타코프', '일론머스크', '타이칸', '획기적', '네비게이션', '최고', '가성비', \n",
    "     '셀토스', '파워큐브', '패밀리카', '세컨카', '내연', '유튜버', '에어콘', '휘발류', '매리트', '베터리', '고속도로', '노답', '코나', '완속', '후발주자', '저속', '고속'\n",
    "    ,'롱 레인지','집 밥','리뷰어','디튠','수도권','타이 칸','풀충전','렉카','도어록','주행 거리','오버스티어']\n",
    "\n",
    "for noun in new_noun:\n",
    "    \n",
    "    jongsung_TF = get_jongsung_TF(noun) \n",
    "    f1.write('{},,,,NNP,*,{},{},*,*,*,*,*\\n'.format(noun, jongsung_TF, noun))\n",
    "        \n",
    "for word in add:\n",
    "    if word in new_noun:\n",
    "        pass\n",
    "    else:\n",
    "        jonsung_TF = get_jongsung_TF(word) \n",
    "        f1.write('{},,,,NNP,*,{},{},*,*,*,*,*\\n'.format(word, jongsung_TF, word))\n",
    "\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f07a5480"
   },
   "source": [
    "#### 6. 불용어 제거 및 Mecab 토큰화(품사태깅 및 명사/형용사 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e77b0786"
   },
   "outputs": [],
   "source": [
    "### mecab 토큰화 및 불용어 처리\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "korean_stopwords_path='C:/users/user/Desktop/연세대 데이터 청년 캠퍼스/프로젝트/텍스트전처리/stopword_수정.txt'\n",
    "\n",
    "#텍스트 파일 오픈\n",
    "with open(korean_stopwords_path,encoding='utf-8') as f:\n",
    "    stopwords=f.readlines()\n",
    "stopwords={x.strip() for x in stopwords}\n",
    "\n",
    "stopwords.update(['전기차','안녕','하세요','전기자동차','차','자동차'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ad29526"
   },
   "outputs": [],
   "source": [
    "# mecab으로 토큰화하여 '단어/품사' 형태로 저장하는 함수 \n",
    "from konlpy.tag import Mecab \n",
    "\n",
    "mecab = Mecab('C:\\mecab\\mecab-ko-dic')\n",
    "significant_tags = ['NNG', 'NNP', 'NNB', 'VA', 'XSA', 'SL'] # 명사, 외국어, 형용사와 관련한 품사만 추출\n",
    "\n",
    "def pos_text_mecab(texts):\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    for sent in texts:\n",
    "        pos_tagged = ''\n",
    "        \n",
    "        for word in mecab.pos(sent):\n",
    "            if (word[1] in significant_tags) & (word[0] not in stopwords):\n",
    "                pos_tagged += word[0].strip() + '/' + word[1] + ' '\n",
    "\n",
    "        corpus.append(pos_tagged.strip())\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "138e5108"
   },
   "outputs": [],
   "source": [
    "# 형용사를 원형 복원하는 함수\n",
    "\n",
    "p1 = re.compile('[가-힣A-Za-z0-9]+/NN. [가-힣A-Za-z0-9]+/XSA') # 명사, 형용사파생접미사 ->형용사\n",
    "p2 = re.compile('[가-힣A-Za-z0-9]+/VA') #형용사\n",
    "\n",
    "def stemming_text(text): \n",
    "    corpus = [] \n",
    "    for sent in text: \n",
    "        ori_sent = sent \n",
    "        \n",
    "        mached_terms = re.findall(p1, ori_sent) \n",
    "        for terms in mached_terms: \n",
    "            ori_terms = terms \n",
    "            modi_terms = '' \n",
    "            for term in terms.split(' '): \n",
    "                lemma = term.split('/')[0] \n",
    "                tag = term.split('/')[-1] \n",
    "                modi_terms += lemma \n",
    "            modi_terms += '다/VA' \n",
    "            ori_sent = ori_sent.replace(ori_terms, modi_terms) \n",
    "   \n",
    "        mached_terms = re.findall(p2, ori_sent) \n",
    "        for terms in mached_terms: \n",
    "            ori_terms = terms \n",
    "            modi_terms = '' \n",
    "            for term in terms.split(' '): \n",
    "                lemma = term.split('/')[0] \n",
    "                tag = term.split('/')[-1] \n",
    "                modi_terms += lemma \n",
    "            if '다' != modi_terms[-1]: \n",
    "                modi_terms += '다' \n",
    "            modi_terms += '/VA' \n",
    "            ori_sent = ori_sent.replace(ori_terms, modi_terms) \n",
    "            \n",
    "        corpus.append(ori_sent) \n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b442ef8"
   },
   "outputs": [],
   "source": [
    "# 형용사만 추출하는 함수 \n",
    "\n",
    "def get_va(texts): \n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    for text in texts:\n",
    "        va_str = ''\n",
    "        \n",
    "        if text == '': #빈 텍스트인 경우  빈 텍스트를 그대로 추가\n",
    "            corpus.append(va_str)\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        for word in text.split(' '):\n",
    "            if word.split('/')[1] == 'VA':\n",
    "                va_str += word.split('/')[0] + ' '\n",
    "        \n",
    "        corpus.append(va_str)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b62c4d14"
   },
   "outputs": [],
   "source": [
    "# 단어의 길이 2이상, 일반명사, 고유명사, 외국어 추출\n",
    "\n",
    "replace_word = {'에어콘':'에어컨', '휘발류':'휘발유', '매리트':'메리트', '베터리':'배터리','주행 거리':'주행거리','집 밥':'집밥',\n",
    "               '타이 칸':'타이칸','롱 레인지':'롱레인지'}\n",
    "\n",
    "def get_nouns(texts): \n",
    "    \n",
    "    corpus = []\n",
    "        \n",
    "    for text in texts:\n",
    "        line = ''\n",
    "        \n",
    "        if text == '': #빈 텍스트인 경우  빈 텍스트를 그대로 추가\n",
    "            corpus.append(line)\n",
    "            continue\n",
    "            \n",
    "        for word in text.split(' '):\n",
    "            word_split = word.split('/')\n",
    "            if (word_split[1] in ['SL', 'NNG', 'NNP']) and (len(word_split[0]) > 1):\n",
    "                if word_split[0] in replace_word.keys():\n",
    "                    line += replace_word.get(word_split[0]) + ' '\n",
    "                    \n",
    "                else:\n",
    "                    line += word_split[0] + ' '\n",
    "\n",
    "        corpus.append(line.strip())\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fa8e604"
   },
   "outputs": [],
   "source": [
    "# 형용사와 명사를 추출하는 함수\n",
    "\n",
    "def get_nounva(texts):\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    for text in texts:\n",
    "        line = ''\n",
    "        \n",
    "        if text == '': #빈 텍스트인 경우  빈 텍스트를 그대로 추가\n",
    "            corpus.append(line)\n",
    "            continue\n",
    "        \n",
    "        for word in text.split(' '):\n",
    "            word_split = word.split('/')\n",
    "            if (word_split[1] in ['SL', 'NNG', 'NNP', 'VA']) and (len(word_split[0]) > 1):\n",
    "                if word_split[0] in replace_word.keys():\n",
    "                    line += replace_word.get(word_split[0]) + ' '\n",
    "                else:\n",
    "                    line += word_split[0] + ' '\n",
    "                    \n",
    "        corpus.append(line.strip())\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6ac7d52"
   },
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(lambda x: x.replace('집 밥','집밥'))\n",
    "data['comment']=data['comment'].apply(lambda x: x.replace('주행 거리','주행거리'))\n",
    "data['comment']=data['comment'].apply(lambda x: x.replace('롱 레인지','롱레인지'))\n",
    "data['comment']=data['comment'].apply(lambda x: x.replace('타이 칸','타이칸'))\n",
    "data['comment']=data['comment'].apply(lambda x: x.replace('XA0',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae728e9b"
   },
   "outputs": [],
   "source": [
    "data['comment_lemma'] = stemming_text(pos_text_mecab(data.comment))\n",
    "data['nouns'] = get_nouns(data['comment_lemma'])\n",
    "data['va'] = get_va(data['comment_lemma'])\n",
    "data['noun_va'] = get_nounva(data['comment_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8b47140"
   },
   "outputs": [],
   "source": [
    "## null값 제거\n",
    "data=data.dropna(subset=['comment_lemma'])\n",
    "data=data.dropna(subset=['nouns'])\n",
    "\n",
    "data=data.reset_index()\n",
    "data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a63c54a3"
   },
   "source": [
    "#### * 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d70ed09"
   },
   "outputs": [],
   "source": [
    "data.to_excel('최종 데이터셋.xlsx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "최종 전처리 코드.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
